import streamlit as st
from langchain_core.messages import HumanMessage
from langchain_groq import ChatGroq   
from dotenv import load_dotenv
import os
import io
from docx import Document
import PyPDF2
from PIL import Image
import pytesseract
import pandas as pd

load_dotenv() 
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
st.set_page_config(page_title="AI d·ªãch ti·∫øng Nh·∫≠t", page_icon="ü§ñ", layout = "centered")

st.title("ü§ñ AI d·ªãch ti·∫øng Nh·∫≠t")
st.markdown("·ª®ng d·ª•ng d·ªãch ti·∫øng Nh·∫≠t s·ª≠ d·ª•ng m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLM) v√† c√°c c√¥ng c·ª• t√≠ch h·ª£p.")

model = ChatGroq(
        groq_api_key=os.getenv("GROQ_API_KEY"),
        model="meta-llama/llama-4-scout-17b-16e-instruct",
        temperature=0
    )

uploaded_file = st.file_uploader(
    "T·∫£i l√™n file vƒÉn b·∫£n/·∫£nh ti·∫øng Nh·∫≠t (txt, docx, pdf, png, jpg, jpeg)", 
    type=["txt", "docx", "pdf", "png", "jpg", "jpeg"]
)

def read_file(uploaded_file):
    text = ""
    if uploaded_file.type == "text/plain":
        text = uploaded_file.read().decode("utf-8")
    elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = Document(uploaded_file)
        text = "\n".join([p.text for p in doc.paragraphs])
    elif uploaded_file.type == "application/pdf":
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        text = "\n".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])
    elif uploaded_file.type in ["image/png", "image/jpeg"]:
        image = Image.open(uploaded_file)
        st.image(image, caption="üì∑ ·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)  
        text = pytesseract.image_to_string(image, lang="jpn")  
    return text

if uploaded_file is not None:
    japanese_text = read_file(uploaded_file)
    st.subheader("üìÑ VƒÉn b·∫£n g·ªëc (ti·∫øng Nh·∫≠t OCR/Text)")
    st.text_area("N·ªôi dung", japanese_text, height=200)

    if st.button("D·ªãch sang Ti·∫øng Vi·ªát"):
        response = model.invoke([
            HumanMessage(
                content=f"D·ªãch ƒëo·∫°n vƒÉn b·∫£n ti·∫øng Nh·∫≠t sau sang ti·∫øng Vi·ªát. "
                        f"Tr√¨nh b√†y ch√∫ th√≠ch theo b·∫£ng 3 c·ªôt: Kanji | Hiragana | Nghƒ©a.\n\n{japanese_text}",
                additional_kwargs={"job_role": "Japanese language teacher"}  
            )
        ])
        
        st.subheader("üìñ B·∫£n d·ªãch & Ch√∫ th√≠ch")
        result_text = response.content
        st.write(result_text)

        try:
            df = pd.read_csv(io.StringIO(result_text), sep="|").dropna(axis=1, how="all")
            st.dataframe(df, use_container_width=True)
        except Exception:
            st.info("üëâ Kh√¥ng ph√¢n t√≠ch ƒë∆∞·ª£c b·∫£ng, hi·ªÉn th·ªã d·∫°ng text.")

        with io.BytesIO() as buffer:
            doc = Document()
            doc.add_heading("B·∫£n d·ªãch & Ch√∫ th√≠ch", level=1)
            doc.add_paragraph(result_text)
            doc.save(buffer)
            buffer.seek(0)
            st.download_button(
                label="‚¨áÔ∏è T·∫£i k·∫øt qu·∫£ (.docx)",
                data=buffer,
                file_name="ket_qua_dich.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
